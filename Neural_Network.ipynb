{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils import data \n",
    "from torch.autograd import Variable \n",
    "import torchvision\n",
    "from torchvision.datasets import mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import Table\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.style.use('fivethirtyeight')\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>time</th> <th>volume</th> <th>min_price</th> <th>max_price</th> <th>avg_price</th> <th>median_price</th> <th>warframe</th> <th>available </th> <th>ducats</th> <th>release</th> <th>hot</th> <th>date</th> <th>weekend</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>2019/1/1 </td> <td>69    </td> <td>56       </td> <td>80       </td> <td>68       </td> <td>70          </td> <td>Banshee </td> <td>4         </td> <td>260   </td> <td>0      </td> <td>1   </td> <td>1   </td> <td>0      </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2019/1/2 </td> <td>74    </td> <td>65       </td> <td>80       </td> <td>72.5     </td> <td>74          </td> <td>Banshee </td> <td>4         </td> <td>260   </td> <td>0      </td> <td>1   </td> <td>2   </td> <td>0      </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2019/1/3 </td> <td>61    </td> <td>61       </td> <td>85       </td> <td>73       </td> <td>75          </td> <td>Banshee </td> <td>4         </td> <td>260   </td> <td>0      </td> <td>1   </td> <td>3   </td> <td>0      </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2019/1/4 </td> <td>50    </td> <td>61       </td> <td>85       </td> <td>73       </td> <td>75          </td> <td>Banshee </td> <td>4         </td> <td>260   </td> <td>0      </td> <td>1   </td> <td>4   </td> <td>0      </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2019/1/5 </td> <td>55    </td> <td>65       </td> <td>80       </td> <td>72.5     </td> <td>73.5        </td> <td>Banshee </td> <td>4         </td> <td>260   </td> <td>0      </td> <td>1   </td> <td>5   </td> <td>1      </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2019/1/6 </td> <td>72    </td> <td>60       </td> <td>80       </td> <td>70       </td> <td>70          </td> <td>Banshee </td> <td>4         </td> <td>260   </td> <td>0      </td> <td>1   </td> <td>6   </td> <td>1      </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2019/1/7 </td> <td>56    </td> <td>65       </td> <td>85       </td> <td>75       </td> <td>75          </td> <td>Banshee </td> <td>4         </td> <td>260   </td> <td>0      </td> <td>1   </td> <td>7   </td> <td>0      </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2019/1/8 </td> <td>59    </td> <td>63       </td> <td>85       </td> <td>74       </td> <td>75          </td> <td>Banshee </td> <td>4         </td> <td>260   </td> <td>0      </td> <td>1   </td> <td>8   </td> <td>0      </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2019/1/9 </td> <td>37    </td> <td>72       </td> <td>80       </td> <td>76       </td> <td>79.5        </td> <td>Banshee </td> <td>4         </td> <td>260   </td> <td>0      </td> <td>1   </td> <td>9   </td> <td>0      </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2019/1/10</td> <td>38    </td> <td>62       </td> <td>84       </td> <td>73       </td> <td>75          </td> <td>Banshee </td> <td>4         </td> <td>260   </td> <td>0      </td> <td>1   </td> <td>10  </td> <td>0      </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (1325 rows omitted)</p>"
      ],
      "text/plain": [
       "time      | volume | min_price | max_price | avg_price | median_price | warframe | available  | ducats | release | hot  | date | weekend\n",
       "2019/1/1  | 69     | 56        | 80        | 68        | 70           | Banshee  | 4          | 260    | 0       | 1    | 1    | 0\n",
       "2019/1/2  | 74     | 65        | 80        | 72.5      | 74           | Banshee  | 4          | 260    | 0       | 1    | 2    | 0\n",
       "2019/1/3  | 61     | 61        | 85        | 73        | 75           | Banshee  | 4          | 260    | 0       | 1    | 3    | 0\n",
       "2019/1/4  | 50     | 61        | 85        | 73        | 75           | Banshee  | 4          | 260    | 0       | 1    | 4    | 0\n",
       "2019/1/5  | 55     | 65        | 80        | 72.5      | 73.5         | Banshee  | 4          | 260    | 0       | 1    | 5    | 1\n",
       "2019/1/6  | 72     | 60        | 80        | 70        | 70           | Banshee  | 4          | 260    | 0       | 1    | 6    | 1\n",
       "2019/1/7  | 56     | 65        | 85        | 75        | 75           | Banshee  | 4          | 260    | 0       | 1    | 7    | 0\n",
       "2019/1/8  | 59     | 63        | 85        | 74        | 75           | Banshee  | 4          | 260    | 0       | 1    | 8    | 0\n",
       "2019/1/9  | 37     | 72        | 80        | 76        | 79.5         | Banshee  | 4          | 260    | 0       | 1    | 9    | 0\n",
       "2019/1/10 | 38     | 62        | 84        | 73        | 75           | Banshee  | 4          | 260    | 0       | 1    | 10   | 0\n",
       "... (1325 rows omitted)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = pd.read_csv('warframe_data.csv')\n",
    "Train=Table.from_df(training)\n",
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 2.6, 0, 1, 0.1, 0],\n",
       " [4, 2.6, 0, 1, 0.2, 0],\n",
       " [4, 2.6, 0, 1, 0.3, 0],\n",
       " [4, 2.6, 0, 1, 0.4, 0],\n",
       " [4, 2.6, 0, 1, 0.5, 1]]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=[]\n",
    "for i in range(1335):\n",
    "    feature1=[]\n",
    "    feature1.append(Train.row(i)[7])\n",
    "    feature1.append(Train.row(i)[8]/100)\n",
    "    feature1.append(Train.row(i)[9])\n",
    "    feature1.append(Train.row(i)[10])\n",
    "    feature1.append(Train.row(i)[11]/10)\n",
    "    feature1.append(Train.row(i)[12])\n",
    "    features.append(feature1)\n",
    "features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[69, 56, 80, 68.0],\n",
       " [74, 65, 80, 72.5],\n",
       " [61, 61, 85, 73.0],\n",
       " [50, 61, 85, 73.0],\n",
       " [55, 65, 80, 72.5]]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=[]\n",
    "for i in range(1335):\n",
    "    label=[]\n",
    "    label.append(Train.row(i)[1])\n",
    "    label.append(Train.row(i)[2])\n",
    "    label.append(Train.row(i)[3])\n",
    "    label.append(Train.row(i)[4])\n",
    "    labels.append(label)\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(6,24) \n",
    "        self.fc2 = nn.Linear(24,12)\n",
    "        self.fc3 = nn.Linear(12,4)\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,labels,features):\n",
    "        super(MyDataset,self).__init__()\n",
    "        self.labels=labels\n",
    "        self.features=features\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    def __getitem__(self,idx):\n",
    "        feature=self.features[idx]\n",
    "        label=self.labels[idx]\n",
    "        return {'feature':feature, 'label':label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(loader):\n",
    "    total_loss=0.0\n",
    "    for i,data in enumerate(loader):\n",
    "        featurest=data['feature'].float()\n",
    "        labelst=data['label'].float()\n",
    "        optimizer.zero_grad()\n",
    "        out=mnet(featurest)\n",
    "        loss=loss_fn(out,labelst)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    print ('loss', total_loss/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 31054.17578125\n",
      "loss 30537.702674278848\n",
      "loss 21208.9208984375\n",
      "loss 10199.054612379809\n",
      "loss 6617.003079927885\n",
      "loss 4120.304912860577\n",
      "loss 3067.138653094952\n",
      "loss 2708.5537391075723\n",
      "loss 2525.2543006310098\n"
     ]
    }
   ],
   "source": [
    "mnet=Net()\n",
    "loss_fn=torch.nn.MSELoss()\n",
    "optimizer=torch.optim.SGD(mnet.parameters(),lr=0.0001,momentum=0.01,weight_decay=1e-8)\n",
    "\n",
    "dataset=MyDataset(np.asarray(labels),np.asarray(features))\n",
    "load=DataLoader(dataset,shuffle=True,batch_size=100)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    train_epoch(load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[171.18152 133.69408 160.19861 146.79666]\n",
      "[169, 138, 164, 151.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(time='2019/1/29', volume=169, min_price=138, max_price=164, avg_price=151.0, median_price=150.0, warframe='Mesa', available =3, ducats=260, release=1, hot=3, date=29, weekend=0)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=562\n",
    "state=features[k]\n",
    "innput=Variable(torch.FloatTensor(state))\n",
    "output=mnet(innput).detach().numpy()\n",
    "print(output)\n",
    "print(labels[k])\n",
    "Train.row(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mnet.state_dict(),'DNNmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
